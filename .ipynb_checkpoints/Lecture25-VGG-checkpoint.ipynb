{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ac28925",
   "metadata": {},
   "source": [
    "###  怎样更好地更深，更大？\n",
    "- 提问:AlexNet比LeNet更深更大，怎样更好地更深，更大？\n",
    "- 选项：\n",
    "1. 更多的全连接层（太贵：大+计算量大）\n",
    "2. 更多的卷积层（在AlexNet的基础上加）\n",
    "3. 将卷积层组合成块->VGG!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cd27f9",
   "metadata": {},
   "source": [
    "## VGG的idea\n",
    "- 实现了VGG块\n",
    "- 实验表明：同样计算开销的情况下，对更多的3 * 3 比堆少一点的5 * 5效果要好\n",
    "- VGG块： 3 * 3卷积（pad = 1）(n层，m通道), 2 * 2最大池化层（stride = 2）\n",
    "![softmax-description](./imgs/25-1.png)\n",
    "\n",
    "## VGG的架构\n",
    "- 多个VGG块后连接全连接层\n",
    "- VGG可以理解为更大更深的VGG\n",
    "![softmax-description](./imgs/25-3.png)\n",
    "\n",
    "## 总结\n",
    "- VGG使用可重复的卷积快来构建深度卷积神经网络\n",
    "- 使用不同卷积块个数和超参数可以得到不同复杂度的变种\n",
    "- VGG-11 使用可复用的卷积块构造网络。不同的 VGG 模型可通过每个块中卷积层数量和输出通道数量的差异来定义。块的使用导致网络定义的非常简洁。使用块可以有效地设计复杂的网络。\n",
    "- 在VGG论文中，Simonyan和Ziserman尝试了各种架构。特别是他们发现深层且窄的卷积（即3×3）比较浅层且宽的卷积更有效。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95983d79",
   "metadata": {},
   "source": [
    "### 卷积输出层的尺寸公式\n",
    "假设：输入图片（Input）大小为I * I，卷积核（Filter）大小为K * K，步长（stride）为S，填充（Padding）的像素数为P，那卷积层输出（Output）的特征图大小为多少呢?\n",
    "\n",
    "可以得出推导公式：\n",
    "\n",
    "$O=((I-K+2P)/S)+1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f302a577",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from torch import nn\n",
    "import d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04897ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造vgg块\n",
    "# Side not\n",
    "def vgg_block(num_convs, in_channels, out_channels):\n",
    "    layers = []\n",
    "    for _ in range(num_convs):\n",
    "        # 这里输入和输出的尺寸是相同的\n",
    "        layers.append(nn.Conv2d(in_channels, out_channels,\n",
    "                                kernel_size=3, padding=1))\n",
    "        \n",
    "        layers.append(nn.ReLU())\n",
    "        in_channels = out_channels\n",
    "    layers.append(nn.MaxPool2d(kernel_size=2,stride=2))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77d19f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造vgg网络\n",
    "# 224/2^5 = 7，7就除不动了，所以是5块\n",
    "# 经典的思想：把网络分成5块，每一块高宽减半，通道数翻倍\n",
    "conv_arch = ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eef6908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG11的结构\n",
    "def vgg(conv_arch):\n",
    "    conv_blks = []\n",
    "    in_channels = 1\n",
    "    # 卷积层部分\n",
    "    for (num_convs, out_channels) in conv_arch:\n",
    "        conv_blks.append(vgg_block(num_convs, in_channels, out_channels))\n",
    "        in_channels = out_channels\n",
    "\n",
    "    return nn.Sequential(\n",
    "        *conv_blks, nn.Flatten(),\n",
    "        # 全连接层部分\n",
    "        nn.Linear(out_channels * 7 * 7, 4096), nn.ReLU(), nn.Dropout(0.5),\n",
    "        nn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(0.5),\n",
    "        nn.Linear(4096, 10))\n",
    "\n",
    "net = vgg(conv_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b24bd6a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-03da120fc0c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'output shape:\\t'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "X = torch.randn(size=(1, 1, 224, 224))\n",
    "for blk in net:\n",
    "    X = blk(X)\n",
    "    print(blk.__class__.__name__,'output shape:\\t',X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "027594c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conv_arch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-615766d517ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# 因为vgg11比AlexNet计算量更大，我们构建了一个通道数较少的网络\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msmall_conv_arch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconv_arch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvgg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmall_conv_arch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'conv_arch' is not defined"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "# 因为vgg11比AlexNet计算量更大，我们构建了一个通道数较少的网络\n",
    "ratio = 4\n",
    "small_conv_arch = [(pair[0], pair[1] // ratio) for pair in conv_arch]\n",
    "net = vgg(small_conv_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e99c446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr会增大一些（随便调的）\n",
    "lr, num_epochs, batch_size = 0.05, 10, 128\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)\n",
    "d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
